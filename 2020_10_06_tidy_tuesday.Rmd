---
title: "TidyTemplate"
date: 2020-10-06
output: html_output
editor_options: 
  chunk_output_type: console
---

# TidyTuesday


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, cache = T,
                      warning = FALSE, message = FALSE,
                      dpi = 180, fig.width = 8, fig.height = 5)

library(tidyverse)
library(tidytuesdayR)
library(scales)
theme_set(theme_light())
```

```{r}
tt <- tt_load("2018-12-04")
medium_dataset <- tt$medium_datasci
```

```{r}
medium_processed <- medium_dataset %>% 
    select(-x1) %>% 
    mutate(post_id = row_number())
```

```{r}
medium_gathered <- medium_processed %>% 
    pivot_longer(tag_ai:tag_machine_learning, names_to = "tag", values_to = "value") %>% 
    mutate(tag = str_remove(tag, "tag_")) %>% 
    filter(value>0)

medium_gathered %>% 
    group_by(tag) %>% 
    summarise(total = sum(value),
              claps = sum(claps)) %>% 
    arrange(-total)

medium_gathered %>% 
    count(tag, sort = T)
```

```{r}
medium_gathered %>% 
    group_by(tag) %>% 
    summarise(claps = median(claps)) %>% 
    arrange(-claps)
```

```{r}
medium_gathered %>% 
    ggplot(aes(claps)) +
    geom_histogram() +
    scale_x_log10(labels = comma_format())
```

```{r}
medium_gathered %>% 
    mutate(reading_time = pmin(10, reading_time)) %>% 
    ggplot(aes(reading_time)) +
    geom_histogram() +
    scale_x_continuous(breaks = seq(2,10,2),
                       labels = c(seq(2,8,2), "10+")) +
    labs(title = "Medain Reading Time for Medium Articles")
```

Lets do some textmining
```{r}
library(tidytext)

medium_words <- medium_processed %>% 
    filter(!is.na(title)) %>% 
    select(post_id, title, subtitle, year, reading_time, claps) %>% 
    unnest_tokens(word, title) %>% 
    anti_join(stop_words, by = "word") %>% 
    filter(!word == "de",
           str_detect(word, "[a-z]")) 

medium_words %>% 
    count(word, sort = T) %>% 
    head(20) %>% 
    ggplot(aes(fct_reorder(word,n), n)) +
    geom_col() +
    coord_flip() +
    labs(title = "Most Common Words in Medium Posts' Titles",
         x = "",
         y = "")
    
```

```{r}
medium_words_filtered <- medium_words %>%
  add_count(word) %>%
  filter(n >= 250)
tag_claps <- medium_words_filtered %>%
  group_by(word) %>%
  summarize(median_claps = median(claps),
            geometric_mean_claps = exp(mean(log(claps + 1))) - 1,
            occurences = n()) %>%
  arrange(desc(median_claps))
```


```{r}
library(widyr)
library(ggraph)
library(igraph)


top_words_cor <- medium_words_filtered %>% 
    select(post_id, word) %>% 
    pairwise_cor(word, post_id, sort = T) %>% 
    head(100)

top_words_cor %>% 
    graph_from_data_frame() %>% 
    ggraph() +
    geom_edge_link() +
    geom_node_point() +
    geom_node_text(aes(label = name), repel = T)

```

```{r}
top_word_cors <- medium_words_filtered %>%
  select(post_id, word) %>%
  pairwise_cor(word, post_id, sort = TRUE) %>%
  head(150)
vertices <- tag_claps %>%
  filter(word %in% top_word_cors$item1 |
           word %in% top_word_cors$item2)
set.seed(2018)
top_word_cors %>%
  graph_from_data_frame(vertices = vertices) %>%
  ggraph() +
  geom_edge_link() +
  geom_node_point(aes(size = occurences * 1.1)) +
  geom_node_point(aes(size = occurences,
                      color = geometric_mean_claps)) +
  geom_node_text(aes(label = name), repel = TRUE) +
  scale_color_gradient2(low = "blue",
                        high = "red",
                        midpoint = 10) +
  theme_void() +
  labs(title = "What gets claps in Medium article titles?",
       subtitle = "Color shows the geometric mean of # of claps on articles with this word in the title",
       size = "# of occurrences",
       color = "Claps")
```

End of script

